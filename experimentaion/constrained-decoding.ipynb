{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "447e1e0e",
   "metadata": {},
   "source": [
    "# Exlopring Constrained Decoding\n",
    "\n",
    "Constrained Decoding is a method that enforce structured outputs from llms. This is done on the logits level, the model is allowed to generate specific logits in specific order.\n",
    "\n",
    "Its different from JSON-mode where llms are fine tuned to generate accurate json.\n",
    "## Requirements\n",
    "- we need to have access to logits from the api provider or use self hosted llms.\n",
    "- openai supports logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b3c9982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e458bb3c",
   "metadata": {},
   "source": [
    "First lets see how effective are logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0c9ef30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18049, 7557, 261, 1058, 13]\n",
      " time\n",
      "[4580]\n",
      "[1058]\n"
     ]
    }
   ],
   "source": [
    "# lets explore the logits for this sentence\n",
    "sentence = \"Once upon a time.\"\n",
    "encoder = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "token_ids = encoder.encode(sentence)\n",
    "print(token_ids)\n",
    "\n",
    "# time has the id 1058 with space\n",
    "token = encoder.decode([1058])\n",
    "print(token)\n",
    "print(encoder.encode(\"time\"))\n",
    "print(encoder.encode(\" time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44f846fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Your job is to finish user's sentences. Keep it to a single sentence.\"\n",
    "user_message = \"Once upon a\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_message}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f319b4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time, in a faraway land, there lived a brave young knight who dreamed of '\n",
      " 'adventure.')\n",
      "[ChatCompletionTokenLogprob(token='time', bytes=[116, 105, 109, 101], logprob=-0.00015633940347470343, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.20142541825771332, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' in', bytes=[32, 105, 110], logprob=-0.010051299817860126, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=0.0, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' far', bytes=[32, 102, 97, 114], logprob=-1.1378127336502075, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token='away', bytes=[97, 119, 97, 121], logprob=-0.005545004736632109, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' land', bytes=[32, 108, 97, 110, 100], logprob=-0.3132808804512024, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.0007227989844977856, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' there', bytes=[32, 116, 104, 101, 114, 101], logprob=-0.014444372616708279, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' lived', bytes=[32, 108, 105, 118, 101, 100], logprob=-0.04017480090260506, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.00015860427811276168, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' brave', bytes=[32, 98, 114, 97, 118, 101], logprob=-0.08587919175624847, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' young', bytes=[32, 121, 111, 117, 110, 103], logprob=-2.386399984359741, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' knight', bytes=[32, 107, 110, 105, 103, 104, 116], logprob=-0.6617245078086853, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' who', bytes=[32, 119, 104, 111], logprob=-1.3150825500488281, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' dreamed', bytes=[32, 100, 114, 101, 97, 109, 101, 100], logprob=-0.17061860859394073, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=0.0, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' adventure', bytes=[32, 97, 100, 118, 101, 110, 116, 117, 114, 101], logprob=-0.01769586093723774, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0006725206621922553, top_logprobs=[])]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# without any restirctions\n",
    "client = OpenAI()\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    logprobs=True\n",
    ")\n",
    "pprint(resp.choices[0].message.content)\n",
    "pprint(resp.choices[0].logprobs.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d45a5f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a midnight dreary, a weary traveler stumbled upon an ancient forest filled '\n",
      " 'with secrets.')\n",
      "[ChatCompletionTokenLogprob(token='a', bytes=[97], logprob=-7.625537872314453, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' midnight', bytes=[32, 109, 105, 100, 110, 105, 103, 104, 116], logprob=-15.375000953674316, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' dre', bytes=[32, 100, 114, 101], logprob=-0.005293054040521383, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token='ary', bytes=[97, 114, 121], logprob=-5.512236498361744e-07, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.4927191436290741, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' weary', bytes=[32, 119, 101, 97, 114, 121], logprob=-2.674888849258423, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' traveler', bytes=[32, 116, 114, 97, 118, 101, 108, 101, 114], logprob=-0.0008652491960674524, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' stumbled', bytes=[32, 115, 116, 117, 109, 98, 108, 101, 100], logprob=-0.06553535908460617, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' upon', bytes=[32, 117, 112, 111, 110], logprob=-0.0005599428550340235, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' an', bytes=[32, 97, 110], logprob=-0.5759398937225342, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' ancient', bytes=[32, 97, 110, 99, 105, 101, 110, 116], logprob=-0.32386651635169983, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' forest', bytes=[32, 102, 111, 114, 101, 115, 116], logprob=-0.7117501497268677, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' filled', bytes=[32, 102, 105, 108, 108, 101, 100], logprob=-0.782270073890686, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' with', bytes=[32, 119, 105, 116, 104], logprob=-1.9361264946837764e-07, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' secrets', bytes=[32, 115, 101, 99, 114, 101, 116, 115], logprob=-0.9962711930274963, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.03224033862352371, top_logprobs=[])]\n"
     ]
    }
   ],
   "source": [
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    logprobs=True,\n",
    "    logit_bias={1058:-100, 4580: -100} # time can occur in two forms with a leading space or a single word without spaces -100 blocks these words\n",
    ")\n",
    "pprint(resp.choices[0].message.content)\n",
    "pprint(resp.choices[0].logprobs.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19ee5262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8837]\n",
      "[9059]\n",
      "[70782]\n",
      "[28854]\n",
      "[6446]\n",
      "[30146]\n",
      "[16798]\n",
      "[154045]\n"
     ]
    }
   ],
   "source": [
    "# Case Two increase likely hood of generating \n",
    "system_prompt = \"Guess what user might like. for one a cat also birds\"\n",
    "user_message = \"which pet do i like?\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_message}\n",
    "]\n",
    "# lets block cat and increase chance of dogs\n",
    "print(encoder.encode(\"cat\"))\n",
    "print(encoder.encode(\" cat\"))\n",
    "pprint(encoder.encode(\"cats\"))\n",
    "print(encoder.encode(\" cats\"))\n",
    "print(encoder.encode(\" dog\"))\n",
    "print(encoder.encode(\"dog\"))\n",
    "print(encoder.encode(\" dogs\"))\n",
    "print(encoder.encode(\"dogs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ce2c357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Based on your mention of liking a dog, a dog would likely be a pet you '\n",
      " 'enjoy! If you have a dog, you might also appreciate dog-related activities '\n",
      " 'or dog breeds.')\n",
      "[ChatCompletionTokenLogprob(token='Based', bytes=[66, 97, 115, 101, 100], logprob=-0.03236684203147888, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' on', bytes=[32, 111, 110], logprob=0.0, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' your', bytes=[32, 121, 111, 117, 114], logprob=-0.10628903657197952, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' mention', bytes=[32, 109, 101, 110, 116, 105, 111, 110], logprob=-0.03819664195179939, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-6.635164754698053e-05, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' liking', bytes=[32, 108, 105, 107, 105, 110, 103], logprob=-0.5692939162254333, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-3.1077194213867188, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' dog', bytes=[32, 100, 111, 103], logprob=-18.0, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-1.3650681972503662, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-1.5003615617752075, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' dog', bytes=[32, 100, 111, 103], logprob=-9999.0, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' would', bytes=[32, 119, 111, 117, 108, 100], logprob=-1.739064335823059, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' likely', bytes=[32, 108, 105, 107, 101, 108, 121], logprob=-0.4043307602405548, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' be', bytes=[32, 98, 101], logprob=-0.00012761499965563416, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.3967418968677521, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' pet', bytes=[32, 112, 101, 116], logprob=-0.08689005672931671, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-0.024985572323203087, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' enjoy', bytes=[32, 101, 110, 106, 111, 121], logprob=-0.014656784012913704, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token='!', bytes=[33], logprob=-0.3168880045413971, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' If', bytes=[32, 73, 102], logprob=-1.2678343057632446, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-0.3014511466026306, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' have', bytes=[32, 104, 97, 118, 101], logprob=-0.7064443230628967, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-1.199662208557129, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' dog', bytes=[32, 100, 111, 103], logprob=-7.6888885498046875, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.6735459566116333, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-0.7761988639831543, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' might', bytes=[32, 109, 105, 103, 104, 116], logprob=-0.48743200302124023, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' also', bytes=[32, 97, 108, 115, 111], logprob=-0.23855900764465332, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' appreciate', bytes=[32, 97, 112, 112, 114, 101, 99, 105, 97, 116, 101], logprob=-0.15528467297554016, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' dog', bytes=[32, 100, 111, 103], logprob=-9999.0, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token='-related', bytes=[45, 114, 101, 108, 97, 116, 101, 100], logprob=-0.049597952514886856, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' activities', bytes=[32, 97, 99, 116, 105, 118, 105, 116, 105, 101, 115], logprob=-0.8915249705314636, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' or', bytes=[32, 111, 114], logprob=-0.7472219467163086, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' dog', bytes=[32, 100, 111, 103], logprob=-5.821543216705322, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token=' breeds', bytes=[32, 98, 114, 101, 101, 100, 115], logprob=-2.19844388961792, top_logprobs=[]),\n",
      " ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.36900997161865234, top_logprobs=[])]\n"
     ]
    }
   ],
   "source": [
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    logprobs=True,\n",
    "    logit_bias={\n",
    "        6446: 10,\n",
    "        30146: 10,\n",
    "        8837: -100,\n",
    "        9059:-100,\n",
    "        70782: -100,\n",
    "        28854:-100\n",
    "    } # 1 is usually enough but for this case 5 for better enforcement 10 will break things\n",
    ")\n",
    "pprint(resp.choices[0].message.content)\n",
    "pprint(resp.choices[0].logprobs.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
